{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h2>Uéliton Viana, Ciêntista de Dados</h2>\n","\n","<a href=\"mailto:ueliton_viana@outlook.com\"><i style=\"font-size:25px; margin-right:10px\" class=\"fa fa-envelope\"></i></a>\n","<a href=\"https://wa.me/5549984233608\"><i style=\"font-size:25px; margin-right:10px\" class=\"fa fa-whatsapp\"></i></a>\n","<a href=\"https://www.linkedin.com/in/ueliton-viana/\"><i style=\"font-size:25px; margin-right:10px\" class=\"fa fa-linkedin\"></i></a>\n","<a href=\"https://github.com/Uellwar\"><i style=\"font-size:25px; margin-right:10px\" class=\"fa fa-github\"></i></a>\n","<a href=\"https://www.instagram.com/uelitonviana_/\"><i style=\"font-size:25x; margin-right:10px\" class=\"fa fa-instagram\"></i></a>\n","<a href=\"https://www.youtube.com/channel/UCX-MsX0Tt-iGBScRhsDfSJA\"><i style=\"font-size:25px; margin-right:10px\" class=\"fa fa-youtube\"></i></a>"]},{"cell_type":"markdown","metadata":{},"source":["Durante minhas férias, decidi me aventurar em um novo projeto de ciência de dados: a construção de um modelo de classificação de sentimentos em comentários de reviews de e-commerce. Utilizei [dados reais](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce) fornecidos pela [Olist](https://olist.com/pt-br/) para treinar os modelos. Para resolver o problema de classificação prévia dos sentimentos nos comentários, escolhi usar a pontuação de avaliação de compra real. Assim, os comentários com notas 1 e 2 são considerados sentimentos negativos, com nota 3 é considerado neutro e os sentimentos positivos foram atribuídos aos comentários com notas 4 e 5.\n","\n","Para desenvolver este projeto, segui algumas etapas importantes: Primeiro, carreguei as bibliotecas, modelos e dados necessários. Em seguida, foi realizada uma limpeza e tratamento dos dados para que eles estivessem prontos para o treinamento do modelo. Depois, apliquei a vectorização e normalização aos dados e reduzi a dimensionalidade deles, para que os modelos pudessem processá-los de forma mais eficiente.\n","Utilizei validação cruzada para selecionar os melhores modelos e, em seguida, realizei o ajuste dos parâmetros dos modelos selecionados usando random search. Depois, avaliei os melhores modelos e os comparei com um modelo em ensemble. Por fim, escrevi um relatório detalhando os principais pontos do trabalho realizado e sugerindo melhorias futuras.\n","\n","---"]},{"cell_type":"markdown","metadata":{},"source":["**Cronograma de etapas do projeto.**\n","\n","Tópicos:\n","\n","✅ 1. Coleta de dados: Coletar dados de comentários e avaliações de produtos em e-commerce.\n","\n","✅ 2. Pré-processamento de dados: Pré-processar os dados coletados, incluindo remoção de ruídos e normalização de texto.\n","\n","✅ 3. Seleção e treinamento de modelo: Selecionar e treinar um modelo de classificação de sentimento que atenda às necessidades do projeto, usando técnicas de aprendizado de máquina para melhorar o desempenho do modelo.\n","\n","✅ 4. Avaliação do desempenho do modelo: Avaliar o desempenho do modelo de classificação de sentimentos, testando-o com dados de teste e ajustando os parâmetros de hiperparâmetros, se necessário.\n","\n","✅ 5. Visualização dos resultados: Exibir os resultados da classificação de sentimentos de maneira gráfica e fácil de interpretar.\n","\n","✅ 6. Conclusão e recomendações: Concluir o projeto e fornecer recomendações para possíveis aplicações futuras.\n","\n","✅ 7. Publicação do projeto: Publicar o projeto e os resultados obtidos de maneira acessível para outros interessados.\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:26.456912Z","iopub.status.busy":"2023-01-07T20:57:26.456427Z","iopub.status.idle":"2023-01-07T20:57:26.475315Z","shell.execute_reply":"2023-01-07T20:57:26.474148Z","shell.execute_reply.started":"2023-01-07T20:57:26.456875Z"},"trusted":true},"outputs":[],"source":["# Listagem dos arquivos disponibilizados pela Olist\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"markdown","metadata":{},"source":["**Dicionário de Dados**\n","\n","| coluna       | tabela utilizada | o que essa coluna significa |\n","|:--------------|:--------------------------|:----------------------------|\n","| mensagem do comentário | olist_reviews.csv | a mensagem escrita pelo cliente quando ele deixou a revisão |\n","| título do comentário | olist_reviews.csv | o título da revisão escrito pelo cliente |\n","| pontuação da revisão | olist_reviews.csv | a pontuação dada pelo cliente na revisão (usada para medir o sentimento)|\n","| preço | olist_order_items.csv | o preço do produto comprado |\n","| preço do frete | olist_order_items.csv | o preço do frete do produto comprado |\n","\n","<br><br>\n","\n","As tabelas olist_customer, olist_order_items, olist_reviews e olist_orders **estão conectadas entre si** através das chaves primárias customer_id, order_id e product_id. A tabela olist_customer fornece informações sobre os clientes, como o ID único do cliente, o código postal e a cidade. A tabela olist_order_items fornece informações sobre os itens da compra, como o ID do pedido, o ID do produto, o ID do vendedor, o preço e o preço do frete. A tabela olist_reviews fornece informações sobre os comentários dos clientes, como o ID do pedido, a pontuação da revisão, o título do comentário, a mensagem do comentário e a data de criação da revisão. Finalmente, a tabela olist_orders fornece informações sobre os pedidos, como o ID do pedido, o ID do cliente, o status do pedido, a data de compra, a data de aprovação, a data de entrega do transportador e a data de entrega estimada.\n","\n","---\n"]},{"cell_type":"markdown","metadata":{},"source":["### Importando os pacotes e as funções"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:26.478076Z","iopub.status.busy":"2023-01-07T20:57:26.477135Z","iopub.status.idle":"2023-01-07T20:57:26.490367Z","shell.execute_reply":"2023-01-07T20:57:26.488813Z","shell.execute_reply.started":"2023-01-07T20:57:26.478041Z"},"trusted":true},"outputs":[],"source":["# Carregamento e manipulação dos dados\n","import pandas as pd\n","import numpy as np\n","import scipy\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Limpeza de dados\n","import re\n","import unidecode\n","\n","# Tokenização\n","import nltk\n","nltk.download('punkt')\n","\n","# Remoção de stopwords\n","from nltk.corpus import stopwords\n","\n","# Stemming\n","from nltk.stem import PorterStemmer\n","\n","# Vectorização\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Normalização\n","from sklearn.preprocessing import StandardScaler\n","\n","# Separação de dados\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","\n","# Construção dos modelos\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import GradientBoostingClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.tree import DecisionTreeClassifier \n","\n","#Modelos usados e descartados\n","# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n","# from sklearn.neural_network import MLPClassifier\n","# from sklearn.naive_bayes import GaussianNB \n","# from sklearn.naive_bayes import BernoulliNB\n","# from sklearn.naive_bayes import MultinomialNB \n","# from sklearn.naive_bayes import ComplementNB \n","# from sklearn.naive_bayes import CategoricalNB \n","# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier \n","# from sklearn.neighbors import KNeighborsClassifier\n","\n","# Escolha dos melhores modelos e parâmetros\n","from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n","from sklearn.feature_selection import SelectFromModel\n","\n","# Avaliação dos modelos\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import confusion_matrix\n","\n","# Salvando e Carregando os modelos\n","import pickle\n","\n","# Visualização\n","import plotly.express as px\n","\n","# Métricas de classificação\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:26.494107Z","iopub.status.busy":"2023-01-07T20:57:26.493106Z","iopub.status.idle":"2023-01-07T20:57:26.505218Z","shell.execute_reply":"2023-01-07T20:57:26.503739Z","shell.execute_reply.started":"2023-01-07T20:57:26.494054Z"},"trusted":true},"outputs":[],"source":["class ProcessadorDados:\n","    def __init__(self):\n","        pass\n","    # função recebe o caminho de um arquivo e retorna um dataframe do pacote pandas com os dados contidos no arquivo.\n","    def importar_dados(self, caminho_arquivo,index_col=None,parse_dates=None):\n","        df = pd.read_csv(caminho_arquivo,index_col=index_col, parse_dates=parse_dates)\n","        return df\n","    \n","# instanciando a classe\n","processador = ProcessadorDados()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:26.555874Z","iopub.status.busy":"2023-01-07T20:57:26.554280Z","iopub.status.idle":"2023-01-07T20:57:26.590870Z","shell.execute_reply":"2023-01-07T20:57:26.588778Z","shell.execute_reply.started":"2023-01-07T20:57:26.555828Z"},"trusted":true},"outputs":[],"source":["# Esta função tem como objetivo compactar um conjunto de dados, onde a variável alvo é definida e a chave de junção entre os dados é definida\n","def compactar(dfs, target, key):\n","    # une os dados contidos em dfs (que é uma lista), usando o método 'outer', usando a chave key para a junção\n","    df_join = dfs[0].merge(right=dfs[1], how='outer', on=key)\n","    df_join= df_join.merge(right=dfs[2], how='outer', on=key)\n","    # remove os valores nulos contidos no df_join\n","    df_join.dropna(inplace=True, axis=0)\n","    # filtra o dataframe com somente os pedidos entregues\n","    df_join = df_join.loc[df_join['order_status']=='delivered']\n","    # define as colunas necessárias para o df_join\n","    cols = ['review_comment_message', 'review_comment_title', 'review_score', 'price', 'freight_value','order_id']\n","    df_join = df_join[cols]\n","    # remove as duplicatas do df_join\n","    df_join = df_join.drop_duplicates(subset='order_id', keep='first')\n","    # o identificador do pedido de X\n","    X = df_join.drop(columns=['order_id'],axis=1)\n","    # define a variável y como sendo o valor da variável alvo\n","    y = df_join[target]\n","    return X,y\n","\n","# Esta função tem como objetivo limpar e tratar os dados, usando as opções fornecidas e ao final, retornar os dados prontos para o modelo aprender com eles\n","def limpa_e_trata(df, opcoes):\n","    # define as colunas de texto que serão tratadas e vetorizadas\n","    colunas = ['review_comment_message', 'review_comment_title']\n","    # verifica quais opções de tratamento serão usadas\n","    for opcao, habilitada in opcoes.items():\n","        # Esta condição verifica se a opção está habilitada\n","        if habilitada:\n","            # Estas condições verificam qual opção está habilitada e fazem o tratamento das colunas de acordo com a opção\n","            if opcao == 'remove_acentuacao':\n","                for col in colunas: \n","                    df[col] = df[col].apply(lambda x: unidecode.unidecode(x))\n","            elif opcao == 'texto_e_numero':\n","                for col in colunas:\n","                    df[col] = df[col].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]','',x))\n","            elif opcao == 'remove_carac_dif':\n","                for col in colunas:\n","                    df[col] = df[col].apply(lambda x: re.sub('[\\n\\r]','',x))\n","            elif opcao == 'tokens':\n","                for col in colunas:\n","                    df[col] = df[col].apply(lambda x: nltk.word_tokenize(x))\n","            elif opcao == 'stemming_radical':\n","                for col in colunas:\n","                    ps = PorterStemmer()\n","                    df[col] = df[col].apply(lambda x: [ps.stem(y) for y in x])\n","            elif opcao == 'stopwords':\n","                for col in colunas:\n","                    stop_words = set(stopwords.words('portuguese'))\n","                    df[col] = df[col].apply(lambda x: [y for y in x if y not in stop_words])\n","    # cria um dataframe somente com as colunas de comentários\n","    df_tratado = df[['review_comment_message', 'review_comment_title']]\n","    # cria uma instância de vetorizador\n","    vetorizador = CountVectorizer()\n","    # vetoriza os comentários da mensagem, de modo a transformar em números que representem sua frequência de ocorrência\n","    vetorizado1 = vetorizador.fit_transform(df_tratado['review_comment_message'].str.join(' ')).toarray()\n","    # transforma a matriz de vetorização em um dataframe para que seja possível usar pd.concat\n","    vetorizado1 = pd.DataFrame(vetorizado1)\n","    # vetoriza os comentários do título\n","    vetorizado2 = vetorizador.fit_transform(df_tratado['review_comment_title'].str.join(' ')).toarray()\n","    # transforma a matriz de vetorização em um dataframe para que seja possível usar pd.concat\n","    vetorizado2 = pd.DataFrame(vetorizado2)\n","    # concatena os dataframes de vetorização das mensagens e dos títulos\n","    df_tratado = pd.concat([vetorizado1, vetorizado2], axis=1)\n","    # renomeia as colunas do dataframe para evitar colunas com numeracao/nome repetida\n","    df_tratado.columns = range(df_tratado.shape[1])\n","    # cria uma instância de normalização\n","    scaler = StandardScaler()\n","    # normaliza os dados do dataframe de vetorização\n","    df_vetor_norma = scaler.fit_transform(df_tratado)\n","    # cria um dataframe com os dados normalizados do vetorizador para que seja possível usar pd.concat\n","    df_coments = pd.DataFrame(df_vetor_norma)\n","    # cria uma instância de normalização\n","    scaler = StandardScaler()\n","    # normaliza os dados de preço e frete\n","    df_normalizado = scaler.fit_transform(df[['price','freight_value']])\n","    # cria um dataframe com os dados normalizados para que seja possível usar pd.concat\n","    df_items = pd.DataFrame(df_normalizado)\n","    # concatena os dataframes de itens e de comentários\n","    df_final = pd.concat([df_items, df_coments], axis=1)\n","    # renomeia as colunas do dataframe\n","    df_final.columns = range(df_final.shape[1])\n","    # retorna os dataframes tratados\n","    return df_final, df_items, df_coments\n","\n","\n","def melhores_modelos(X_train, y_train, modelos):\n","    # cria lista de dicionários que armazenarão os resultados\n","    resultados = {'modelo':[], 'acuracia':[]}\n","    # uma iteração para cada modelo na lista de modelos\n","    for modelo in modelos:\n","        # cria o objeto\n","        modelo = modelo()\n","        # cria o objeto de cross validation\n","        cv = KFold(n_splits=3, shuffle=True, random_state=42)\n","        # treina o modelo\n","        scores = cross_val_score(modelo, X_train, y_train, cv=cv, scoring='accuracy')\n","        for score in scores:\n","            # armazena os resultados\n","            resultados['modelo'].append(str(modelo).split('(')[0])\n","            resultados['acuracia'].append(score)\n","    # cria o dataframe de resultados\n","    df_metricas = pd.DataFrame(resultados)\n","    # gera o gráfico\n","    fig_boxplot = px.box(df_metricas, y='acuracia', x='modelo', color='modelo')\n","    # calcula a média da ponturação de cada modelo\n","    df_metricas = df_metricas.groupby('modelo').agg('mean').reset_index()\n","    # atribui uma coluna com o total de características presente nos dados\n","    df_metricas['n_colunas'] =  X_train.shape[1]\n","    # retorna o dataframe e o gráfico\n","    return df_metricas, fig_boxplot\n","\n","# essa função reduz a dimensioalidade dos dados com base na importancia das características\n","def reducao_dimensionalidade(X_train, y_train, n_features):\n","    # Treina uma árvore de decisão\n","    model = DecisionTreeClassifier()\n","    model.fit(X_train, y_train)\n","    # Seleciona as características mais importantes com base na importância dada pelo modelo\n","    selector = SelectFromModel(model, max_features=n_features)\n","    selector.fit(X_train, y_train)\n","    selecionadas = selector.get_support()\n","    # Cria um dataframe com as características selecionadas\n","    X_train_reduzido = X_train.loc[:, selecionadas]\n","    return X_train_reduzido\n","\n","# essa função recebe um modelo, os dados e uma lista de possíveis parametros e retorna o modelo otimizado e outras características extraídas desse modelo\n","def tunagem_de_modelo(modelo, X_train, y_train, lista_parametros):\n","    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3)\n","    opt = RandomizedSearchCV(modelo, lista_parametros,cv=3,verbose=2)\n","    opt.fit(X_train, y_train)\n","    modelo_otimizado = opt.best_estimator_\n","    best_params = opt.best_params_\n","    accuracy = opt.best_score_\n","        \n","    y_pred = modelo_otimizado.predict(X_valid)\n","    df_summary = pd.DataFrame(classification_report(y_valid, y_pred, output_dict=True))\n","    conf_matrix = confusion_matrix(y_valid, y_pred)\n","    df_conf_matrix = pd.DataFrame(conf_matrix, index=['Real 1', 'Real 2', 'Real 3'], columns=['Predito 1', 'Predito 2', 'Predito 3'])\n","    return modelo_otimizado, best_params, accuracy, df_summary,df_conf_matrix\n","\n","# essa função cria um modelo ensemble a partir de outros modelos e fita o ensemble em dados ainda nao vistos por nenhum modelo\n","def ensemble_modelos(modelos, X_train, y_train):\n","    from sklearn.ensemble import VotingClassifier\n","    model_list = []\n","    for model in modelos:\n","        model_list.append((str(model), model))\n","    # adicionando o argumento n_jobs=-1 para permitir que o modelo utilize todos os processadores de cores disponíveis.\n","    ensemble_model = VotingClassifier(estimators=model_list, voting='hard', n_jobs=-1) \n","    ensemble_model.fit(X_train, y_train)\n","    return ensemble_model\n","\n","# função responsável por salvar modelos para uso posterior\n","def salvar_modelo(modelo, path):\n","    \"\"\"Salva um modelo em um arquivo no caminho especificado.\n","    Args:\n","        model: modelo a ser salvo.\n","        path: caminho para onde o modelo será salvo.\"\"\"\n","    with open(path, \"wb\") as f:\n","        pickle.dump(modelo, f)\n","\n","# função responsável por carregar modelos salvos\n","def carregar_modelo(path):\n","    \"\"\"Carrega um modelo salvo em um arquivo no caminho especificado.\n","    \n","    Args:\n","        path: caminho para o arquivo onde o modelo está salvo.\n","        \n","    Returns:\n","        model: modelo carregado.\"\"\"\n","    with open(path, \"rb\") as f:\n","        model = pickle.load(f)\n","    return model\n","\n","# função calcula as 4 principais métricas para problemas de classificação multilabel e retorna um dataframe com os valores de cada uma\n","def metricas_finais(X_test_test, y_test_test, modelos):\n","    # Lista de métricas\n","    metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n","    # Dicionário para armazenar os resultados\n","    results = {}\n","    # Itera sobre todos os modelos\n","    for model in modelos:\n","        # Instancia o modelo\n","        model_obj = model\n","        # Realiza a previsão\n","        y_pred = model_obj.predict(X_test_test)\n","        # Calcula as métricas\n","        accuracy = accuracy_score(y_test_test, y_pred)\n","        precision = precision_score(y_test_test, y_pred, average='macro')\n","        recall = recall_score(y_test_test, y_pred, average='macro')\n","        f1 = f1_score(y_test_test, y_pred, average='macro')\n","        # Adiciona os resultados ao dicionário\n","        results[str(model).split('(')[0]] = [accuracy, precision, recall, f1]\n","    # Cria o DataFrame com os resultados\n","    df = pd.DataFrame(results, index=metrics).T\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["### Coletando os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:26.593008Z","iopub.status.busy":"2023-01-07T20:57:26.592729Z","iopub.status.idle":"2023-01-07T20:57:26.989673Z","shell.execute_reply":"2023-01-07T20:57:26.987778Z","shell.execute_reply.started":"2023-01-07T20:57:26.592983Z"},"trusted":true},"outputs":[],"source":["# Esse código importa dados de um arquivo CSV, seleciona algumas colunas, remove linhas com dados faltantes, \n","# substitui valores faltantes, reseta os índices e amostra 5 linhas aleatórias.\n","\n","df_coment = processador.importar_dados('/kaggle/input/brazilian-ecommerce/olist_order_reviews_dataset.csv')\n","df_coment = df_coment[['order_id','review_id','review_comment_message','review_comment_title','review_score']]\n","df_coment.dropna(subset=['review_comment_message'], inplace=True)\n","df_coment['review_comment_title'] = df_coment['review_comment_title'].replace(np.nan, 'Não Respondeu')\n","df_coment.reset_index(inplace=True)\n","df_coment.drop('index',axis=1,inplace=True)\n","df_coment.loc[df_coment['review_score'] == 2,'review_score'] = 1\n","df_coment.loc[df_coment['review_score'] == 4,'review_score'] = 5\n","df_coment.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:26.991753Z","iopub.status.busy":"2023-01-07T20:57:26.991335Z","iopub.status.idle":"2023-01-07T20:57:27.231574Z","shell.execute_reply":"2023-01-07T20:57:27.230332Z","shell.execute_reply.started":"2023-01-07T20:57:26.991719Z"},"trusted":true},"outputs":[],"source":["# Esse código importa dados, seleciona algumas colunas, e amostra 5 linhas aleatórias. \n","\n","df_item_do_pedido = processador.importar_dados('/kaggle/input/brazilian-ecommerce/olist_order_items_dataset.csv')\n","df_item_do_pedido = df_item_do_pedido[['order_id','product_id','seller_id','price','freight_value']]\n","df_item_do_pedido.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:27.234792Z","iopub.status.busy":"2023-01-07T20:57:27.233948Z","iopub.status.idle":"2023-01-07T20:57:27.593062Z","shell.execute_reply":"2023-01-07T20:57:27.592421Z","shell.execute_reply.started":"2023-01-07T20:57:27.234760Z"},"trusted":true},"outputs":[],"source":["# Esse código importa dados, seleciona algumas colunas, e amostra 5 linhas aleatórias.\n","\n","df_vendas = processador.importar_dados('/kaggle/input/brazilian-ecommerce/olist_orders_dataset.csv')\n","df_vendas = df_vendas[['order_id','customer_id','order_status','order_approved_at','order_delivered_customer_date','order_estimated_delivery_date']]\n","df_vendas.sample(5)"]},{"cell_type":"markdown","metadata":{},"source":["### Pré-processamento de dados"]},{"cell_type":"markdown","metadata":{},"source":["#### Lista das etapas utilizadas:\n","\n","1. Limpeza de dados: É necessário remover caracteres especiais, pontuação, espaços em branco e outros caracteres indesejados dos dados para que possamos obter resultados mais precisos. Se não limparmos os dados, os resultados podem ser imprecisos.\n","\n","2. Tokenização: É necessário separar os dados em tokens usando a biblioteca NLTK para que possamos trabalhar com eles. Se não tokenizarmos os dados, não poderemos realizar nenhuma análise.\n","\n","3. Stemming: É necessário aplicar o processo de stemming nos tokens usando a biblioteca NLTK para reduzir a dimensionalidade dos dados. Se não aplicarmos o processo de stemming, os dados podem ter uma dimensionalidade muito alta, aumento diretamente o custo computacional.\n","\n","4. Lemmatization: É necessário aplicar o processo de lematização nos tokens usando a biblioteca NLTK para reduzir a dimensionalidade dos dados.\n","\n","5. Remoção de stopwords: É necessário remover as stopwords para reduzir a dimensionalidade dos dados.\n","\n","6. Vectorização: É necessário transformar os tokens em vetores para que possamos trabalhar com eles. Se não vectorizarmos os dados, não poderemos realizar nenhuma análise.\n","\n","7. Normalização: É necessário normalizar os vetores usando a biblioteca Scikit-learn para que possamos obter resultados mais precisos. Se não normalizarmos os dados, os resultados podem ser imprecisos."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:27.595093Z","iopub.status.busy":"2023-01-07T20:57:27.594707Z","iopub.status.idle":"2023-01-07T20:57:27.922327Z","shell.execute_reply":"2023-01-07T20:57:27.920777Z","shell.execute_reply.started":"2023-01-07T20:57:27.595060Z"},"trusted":true},"outputs":[],"source":["# Esse código cria um conjunto de dados X e y para treinamento de um modelo de Machine Learning a partir de três \n","# dataframes diferentes (df_coment, df_vendas e df_item_do_pedido). O conjunto de dados X é obtido pela função compactar(), \n","# que seleciona df_coment e outros dois dataframes df_vendas e df_item_do_pedido. \n","# O conjunto de dados y é obtido pela variável \"target\" (review_score). A variável \"key ou chave primária\" (order_id) é usada para unir os três dataframes.\n","\n","dfs = [df_coment.sample(1000), df_vendas,df_item_do_pedido]\n","target='review_score'\n","key='order_id'\n","X, y = compactar(dfs, target, key)\n","X"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:27.924760Z","iopub.status.busy":"2023-01-07T20:57:27.924255Z","iopub.status.idle":"2023-01-07T20:57:28.467847Z","shell.execute_reply":"2023-01-07T20:57:28.466530Z","shell.execute_reply.started":"2023-01-07T20:57:27.924723Z"},"trusted":true},"outputs":[],"source":["# Esse código cria um dicionário de tratamentos, executa a limpeza e tratamento dos dados, e depois faz a divisão entre treino e teste.\n","\n","tratamentos = {\n","            'remove_acentuacao': True, \n","            'texto_e_numero': True, \n","            'remove_carac_dif': True, \n","            'tokens': True, \n","            'stemming_radical': True, \n","            'stopwords': True\n","            }\n","X_full_norm, X_coments, X_items = limpa_e_trata(X, tratamentos)\n","X_train, X_test, y_train, y_test = train_test_split(X_full_norm, y, test_size=0.3, stratify=y, shuffle=True, random_state=1)\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:28.470248Z","iopub.status.busy":"2023-01-07T20:57:28.469502Z","iopub.status.idle":"2023-01-07T20:57:28.493104Z","shell.execute_reply":"2023-01-07T20:57:28.492393Z","shell.execute_reply.started":"2023-01-07T20:57:28.470204Z"},"trusted":true},"outputs":[],"source":["display(X_train.head(3))\n","X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:28.494745Z","iopub.status.busy":"2023-01-07T20:57:28.494017Z","iopub.status.idle":"2023-01-07T20:57:28.991585Z","shell.execute_reply":"2023-01-07T20:57:28.990460Z","shell.execute_reply.started":"2023-01-07T20:57:28.494720Z"},"trusted":true},"outputs":[],"source":["# Esse código reduz a dimensionalidade dos dados de treinamento (X_train) para 10, 25, 50 e 150 características usando um algoritmo de redução de dimensionalidade.\n","\n","X_train_reduzido10 = reducao_dimensionalidade(X_train, y_train, n_features=10)\n","X_train_reduzido25 = reducao_dimensionalidade(X_train, y_train, n_features=25)\n","X_train_reduzido50 = reducao_dimensionalidade(X_train, y_train, n_features=50)\n","X_train_reduzido150 = reducao_dimensionalidade(X_train, y_train, n_features=150)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:28.993096Z","iopub.status.busy":"2023-01-07T20:57:28.992815Z","iopub.status.idle":"2023-01-07T20:57:46.840182Z","shell.execute_reply":"2023-01-07T20:57:46.838695Z","shell.execute_reply.started":"2023-01-07T20:57:28.993072Z"},"trusted":true},"outputs":[],"source":["#Esse código executa vários modelos de classificação com diferentes datasets, calculando uma métrica de acurácia, para comparar os melhores resultados.\n","\n","datas = [X_train_reduzido10,X_train_reduzido25,X_train_reduzido50,X_train_reduzido150]\n","modelos = [LGBMClassifier, GradientBoostingClassifier, LogisticRegression, SVC]\n","metrica = 'acuracia'\n","df_metricas_geral = pd.DataFrame(columns=['modelo',metrica,'n_colunas'])\n","n=1\n","for dataframe in datas:\n","    df_metricas, fig_boxplot = melhores_modelos(dataframe, y_train, modelos=modelos)\n","    fig_boxplot.show()\n","    df_metricas_geral = pd.concat([df_metricas_geral, df_metricas])\n","    print(f'{n}º (de {len(datas)}) Dataset Concluido!. \\ncols: {dataframe.shape[1]}')\n","    n += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:46.844072Z","iopub.status.busy":"2023-01-07T20:57:46.843733Z","iopub.status.idle":"2023-01-07T20:57:46.865533Z","shell.execute_reply":"2023-01-07T20:57:46.864443Z","shell.execute_reply.started":"2023-01-07T20:57:46.844044Z"},"trusted":true},"outputs":[],"source":["# Este código salva um dataframe como um arquivo CSV, agrupa os dados por dois campos, e os ordena por acurácia.\n","\n","df_metricas_geral.to_csv('df_metricas_geral_cv_nFull.csv',index=False)\n","#df_metricas_geral = pd.read_csv('/kaggle/working/df_metricas_geral_cv.csv')\n","df_metricas_geral = df_metricas_geral.groupby(['modelo','n_colunas']).agg('mean').reset_index()\n","df_metricas_geral.sort_values('acuracia',ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:46.868055Z","iopub.status.busy":"2023-01-07T20:57:46.866907Z","iopub.status.idle":"2023-01-07T20:57:46.935794Z","shell.execute_reply":"2023-01-07T20:57:46.934844Z","shell.execute_reply.started":"2023-01-07T20:57:46.868014Z"},"trusted":true},"outputs":[],"source":["# Esse código desenha um gráfico de linha usando os dados de um DataFrame, plotando a acurácia em relação ao número de colunas para cada modelo.\n","px.line(df_metricas_geral, x='n_colunas',y='acuracia', color='modelo')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:46.937431Z","iopub.status.busy":"2023-01-07T20:57:46.937076Z","iopub.status.idle":"2023-01-07T20:57:46.963043Z","shell.execute_reply":"2023-01-07T20:57:46.961817Z","shell.execute_reply.started":"2023-01-07T20:57:46.937405Z"},"trusted":true},"outputs":[],"source":["display(X_test.head(3))\n","X_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:46.966946Z","iopub.status.busy":"2023-01-07T20:57:46.966588Z","iopub.status.idle":"2023-01-07T20:57:46.994271Z","shell.execute_reply":"2023-01-07T20:57:46.993355Z","shell.execute_reply.started":"2023-01-07T20:57:46.966916Z"},"trusted":true},"outputs":[],"source":["# Esse código cria um novo conjunto de dados (dataset_campeão) a partir da variável X_train_reduzido150 e atribui as \n","# variáveis X_train e X_test a esses dados. Ele também exibe o cabeçalho de 3 linhas do X_test e exibe o formato do X_test.\n","\n","dataset_campeao = X_train_reduzido150.copy()\n","X_train = dataset_campeao\n","X_test = X_test[dataset_campeao.columns.to_list()]\n","display(X_test.head(3))\n","X_test.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Tunagem dos melhores modelos\n","\n","#### métricas avaliadas\n","• accuracy: essa métrica mede quantas vezes o modelo acertou as previsões. Quanto mais perto de 100%, melhor o modelo está se saindo.\n","\n","• precision: essa métrica mede o quanto o modelo consegue acertar quando diz que algo é da classe X. Se o modelo tem uma precisão alta, é porque ele raramente diz que algo é da classe X quando na verdade não é.\n","\n","• recall: essa métrica mede o quanto o modelo consegue encontrar todas as coisas da classe X. Se o modelo tem um recall alto, é porque ele consegue encontrar a maioria das coisas da classe X.\n","\n","• f1-score*: essa métrica combina a precisão e o recall em um único número. Quanto mais perto de 100%, melhor o modelo está se saindo.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-07T20:57:46.996273Z","iopub.status.busy":"2023-01-07T20:57:46.995731Z"},"trusted":true},"outputs":[],"source":["# Esse código cria um modelo de Gradient Boosting e realiza uma otimização de parâmetros para encontrar os melhores resultados.\n","params_gbm = {\n","    \"loss\": [\"deviance\", \"exponential\"], # função de custo para minimizar\n","    \"learning_rate\": scipy.stats.uniform(0.01, 0.2), # taxa de aprendizado\n","    \"n_estimators\": scipy.stats.randint(50, 500), # número de árvores\n","    \"max_depth\": scipy.stats.randint(1, 10), # profundidade máxima das árvores\n","    \"min_samples_split\": scipy.stats.randint(2, 20), # número mínimo de amostras para realizar split em um nó\n","    \"min_samples_leaf\": scipy.stats.randint(1, 20), # número mínimo de amostras em cada folha das árvores\n","    \"max_features\": [\"auto\", \"sqrt\", \"log2\", None], # número máximo de features a serem consideradas em cada split\n","}\n","\n","modelo1_gb = GradientBoostingClassifier(random_state=42)\n","modelo1_gb, best_params_gb, accuracy_gb, df_report_gb, mat_conf_gb = tunagem_de_modelo(modelo1_gb, X_train, y_train, params_gbm)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando os melhores parametros\n","best_params_gb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando a acurácia do modelo nos dados de treino\n","accuracy_gb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando as principais métricas do modelo nos dados de treino\n","df_report_gb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando a matriz de confusão usando dados de treino\n","mat_conf_gb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Criando um dataframe com dados sobre os comentários negativos (classe 1)\n","\n","models_metricas_neg = df_report_gb[['1.0']]\n","models_metricas_neg.columns = ['mod1_gb']\n","models_metricas_neg"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Salvando e Carregando o modelo\n","\n","#salvar_modelo(modelo1_gb,'/kaggle/working/modelo1_gb_nFull.pkl')\n","#modelo1_gb = carregar_modelo('/kaggle/input/modelo1-gb/modelo1_gb.pkl')"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Esse código cria um modelo de LGBMClassifier e realiza uma otimização de parâmetros para encontrar os melhores resultados.\n","params_lgbm = {\n","    \"learning_rate\": scipy.stats.uniform(0.01, 0.2), # taxa de aprendizado\n","    \"n_estimators\": scipy.stats.randint(50, 500), # número de árvores\n","    \"max_depth\": scipy.stats.randint(1, 10), # profundidade máxima das árvores\n","    \"num_leaves\": scipy.stats.randint(2, 50), # número máximo de folhas em cada árvore\n","    \"min_child_samples\": scipy.stats.randint(1, 20), # número mínimo de amostras em cada nó interno da árvore\n","    \"subsample\": scipy.stats.uniform(0.01, 1.0), # proporção da amostra a ser usada para treinar cada árvore\n","    \"subsample_freq\": scipy.stats.randint(1, 10), # frequência com que o bagging é aplicado\n","    \"colsample_bytree\": scipy.stats.uniform(0.01, 1.0), # proporção de features a serem consideradas em cada split\n","}\n","\n","modelo2_lgbm = LGBMClassifier(random_state=123)\n","modelo2_lgbm, best_params_lgbm, accuracy_lgbm, df_report_lgbm, mat_conf_lgbm = tunagem_de_modelo(modelo2_lgbm, X_train, y_train, params_lgbm)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando os melhores parametros\n","best_params_lgbm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando a acurácia do modelo nos dados de treino\n","accuracy_lgbm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando as principais métricas do modelo nos dados de treino\n","df_report_lgbm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando a matriz de confusão usando dados de treino\n","mat_conf_lgbm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Criando um dataframe com dados sobre os comentários negativos (classe 1)\n","\n","models_metricas_neg['mod2_lgbm'] = df_report_lgbm[['1.0']]\n","models_metricas_neg"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Salvando e Carregando o modelo\n","\n","#salvar_modelo(modelo2_lgbm,'/kaggle/working/modelo2_lgbm_nFull.pkl')\n","#modelo2_lgbm = carregar_modelo('/kaggle/input/modelo2-lgbm/modelo2_lgbm.pkl')"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Esse código cria um modelo de LogisticRegression e realiza uma otimização de parâmetros para encontrar os melhores resultados.\n","params_logistic_reg = {\n","    \"penalty\": [\"l1\", \"l2\"], # tipo de regularização a ser utilizada\n","    \"C\": scipy.stats.uniform(0.01, 10), # valor do inverso do parâmetro de regularização\n","    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"], # solver a ser utilizado para otimizar a função de custo\n","    \"max_iter\": scipy.stats.randint(100, 1000), # número máximo de iterações do solver\n","}\n","\n","modelo3_lr = LogisticRegression()\n","modelo3_lr, best_params_lr, accuracy_lr, df_report_lr, mat_conf_lr = tunagem_de_modelo(modelo3_lr, X_train, y_train, params_logistic_reg)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando os melhores parametros\n","best_params_lr"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando a acurácia do modelo nos dados de treino\n","accuracy_lr"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando as principais métricas do modelo nos dados de treino\n","df_report_lr"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando a matriz de confusão usando dados de treino\n","mat_conf_lr"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Criando um dataframe com dados sobre os comentários negativos (classe 1)\n","\n","models_metricas_neg['mod3_reg_logist'] = df_report_lr['1.0']\n","models_metricas_neg"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Salvando e Carregando o modelo\n","\n","#salvar_modelo(modelo3_lr,'/kaggle/working/modelo3_lr_nFull.pkl')\n","#modelo3_lr = carregar_modelo('/kaggle/input/modelo3_lr/modelo3_lr.pkl')"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Esse código cria um modelo de SVC e realiza uma otimização de parâmetros para encontrar os melhores resultados.\n","params_svm = {\n","    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n","    \"C\": scipy.stats.uniform(0.01, 10),\n","    \"degree\": scipy.stats.randint(2, 5),\n","    \"gamma\": [\"scale\", \"auto\"] + [scipy.stats.uniform(0.01, 10).rvs()]\n","}\n","\n","# Instância do modelo\n","modelo4_svm = SVC(random_state=42)\n","\n","# Chamada da função de tunagem de modelo\n","modelo4_svm, best_params_svm, accuracy_svm, df_report_svm, mat_conf_svm = tunagem_de_modelo(modelo4_svm, X_train, y_train, params_svm)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando os melhores parametros\n","best_params_svm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando a acurácia do modelo nos dados de treino\n","accuracy_svm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando as principais métricas do modelo nos dados de treino\n","df_report_svm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando a matriz de confusão usando dados de treino\n","mat_conf_svm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Criando um dataframe com dados sobre os comentários negativos (classe 1)\n","\n","models_metricas_neg['mod4_SVM'] = df_report_svm['1.0']\n","models_metricas_neg"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Salvando e Carregando o modelo\n","\n","#salvar_modelo(modelo4_svm,'/kaggle/working/modelo4_svm_nFull.pkl')\n","#modelo4_svm = carregar_modelo('/kaggle/input/modelo4_svm/modelo4_svm.pkl')"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["modelos_tunados = [modelo1_gb,modelo2_lgbm,modelo3_lr,modelo4_svm]\n","X_test_train, X_test_test, y_test_train, y_test_test = train_test_split(X_test, y_test, test_size=0.3, shuffle=True, random_state=42)\n","\n","ensemble_model = ensemble_modelos(modelos_tunados, X_test_train, y_test_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Avaliando o desempenho do modelo Ensemble\n","y_test_pred = ensemble_model.predict(X_test_test)\n","df_report_ensemb = pd.DataFrame(classification_report(y_test_test, y_test_pred, output_dict=True))\n","conf_matrix_ensemb = confusion_matrix(y_test_test, y_test_pred)\n","df_conf_matrix_ensemb = pd.DataFrame(conf_matrix_ensemb, index=['Real 1', 'Real 2', 'Real 3'], columns=['Predito 1', 'Predito 2', 'Predito 3'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando as 5 primeiras previsões\n","y_test_pred[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando as principais métricas do modelo nos dados de treino\n","df_report_ensemb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Mostrando a matriz de confusão usando dados de treino\n","df_conf_matrix_ensemb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Criando um dataframe com dados sobre os comentários negativos (classe 1)\n","\n","models_metricas_neg['mod5_ensemble'] = df_report_ensemb['1.0']\n","models_metricas_neg"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Baixando as metricas dos modelos para um arquivo csv\n","#models_metricas_neg.to_csv('df_metricas_neg_nFull.csv',index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Salvando e Carregando o modelo\n","\n","#salvar_modelo(ensemble_model,'/kaggle/working/ensemble_model_nFull.pkl')\n","#ensemble_model = carregar_modelo('/kaggle/input/ensemble-model-nfull/ensemble_model_nFull.pkl')\n"]},{"cell_type":"markdown","metadata":{},"source":["### Avaliação do desempenho do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Esse código seleciona os modelos criados e calcula as principais métricas de avaliação, dessa vez, para dados de teste\n","\n","modelos_pra_teste = [modelo1_gb,modelo2_lgbm,modelo3_lr,modelo4_svm,ensemble_model]\n","df_metricas_teste = metricas_finais(X_test, y_test, modelos_pra_teste)\n","df_metricas_teste.style.background_gradient()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#df_metricas_teste.to_csv('df_metricas_dados_de_teste_nFull.csv',index=False)"]},{"cell_type":"markdown","metadata":{},"source":["O modelo VotingClassifier obteve as melhores métricas de acurácia e f1-score. Ele é um modelo ensemble, o que significa que é composto por múltiplos modelos trabalhando juntos, o que pode resultar em uma previsão mais robusta e precisa. O modelo GradientBoostingClassifier foi o segundo colocado e é mais rápido que o VotingClassifier, mas possui métricas um pouco inferiores. Ele pode ser uma opção em casos onde o tempo é um fator crítico."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Esse código cria um gráfico de barras comparando as métricas de desempenho de quatro modelos de classificação.\n","import plotly.graph_objects as go\n","\n","x = ['GradientBoostingClassifier', 'LGBMClassifier', 'SVC', 'VotingClassifier']\n","\n","# Criando os subplots\n","fig = go.Figure()\n","\n","# Subplot 1\n","fig.add_trace(go.Bar(x=df_metricas_teste.index, y=df_metricas_teste['accuracy'], name='Acuracia'))\n","\n","# Subplot 2\n","fig.add_trace(go.Bar(x=df_metricas_teste.index, y=df_metricas_teste['precision'], name='Precisão'))\n","\n","# Subplot 3\n","fig.add_trace(go.Bar(x=df_metricas_teste.index, y=df_metricas_teste['recall'], name='Recall'))\n","\n","# Subplot 4\n","fig.add_trace(go.Bar(x=df_metricas_teste.index, y=df_metricas_teste['f1_score'], name='F1 Score'))\n","\n","# Update layout\n","fig.update_layout(title='Métricas do Desempenho dos modelos')\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Apresentação dos resultados, Considerações e Upgrades"]},{"cell_type":"markdown","metadata":{},"source":["Após analisarmos os comentários de reviews de e-commerce com nosso projeto de classificação de sentimentos, pudemos constatar que o modelo VotingClassifier foi robusto e preciso para a solução do problema. Além disso, os resultados obtidos pelo modelo GradientBoostingClassifier foram promissores, oferecendo uma alternativa viável quando o tempo de processamento é uma questão crucial.\n","\n","Embora os resultados obtidos neste projeto sejam promissores, é importante lembrar que eles foram obtidos a partir de um conjunto específico de dados e parâmetros. Portanto, é recomendado realizar testes adicionais para avaliar a generalização dos modelos em outros contextos e garantir sua eficiência. Além disso, é sempre importante considerar se outros modelos ou técnicas poderiam ser úteis no problema em questão. Como profissionais da área de ciência de dados, é fundamental sermos críticos e buscar sempre a melhor solução para cada problema, de forma a garantir resultados precisos e confiáveis. Isso nos permite trabalhar de forma eficiente e proporcionar soluções valiosas para nossos clientes."]},{"cell_type":"markdown","metadata":{},"source":["<a href=\"mailto:ueliton_viana@outlook.com\"><i style=\"font-size:25px; margin-right:10px\" class=\"fa fa-envelope\"></i></a>\n","<a href=\"https://wa.me/5549984233608\"><i style=\"font-size:25px; margin-right:10px\" class=\"fa fa-whatsapp\"></i></a>\n","<a href=\"https://www.linkedin.com/in/ueliton-viana/\"><i style=\"font-size:25px; margin-right:10px\" class=\"fa fa-linkedin\"></i></a>\n","<a href=\"https://github.com/Uellwar\"><i style=\"font-size:25px; margin-right:10px\" class=\"fa fa-github\"></i></a>\n","<a href=\"https://www.instagram.com/uelitonviana_/\"><i style=\"font-size:25x; margin-right:10px\" class=\"fa fa-instagram\"></i></a>\n","<a href=\"https://www.youtube.com/channel/UCX-MsX0Tt-iGBScRhsDfSJA\"><i style=\"font-size:25px; margin-right:10px\" class=\"fa fa-youtube\"></i></a>\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"82bca53e3f5f9ca42386d58d2e7c6fb0d60555593a0b71cbf169e68de1422570"}}},"nbformat":4,"nbformat_minor":4}
